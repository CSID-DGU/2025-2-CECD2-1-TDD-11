from promptflow.core import tool
from typing import Dict, List, Tuple
import json
import re
import sys
import os
import time
from uuid import uuid4

# engine ëª¨ë“ˆ import ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(__file__)
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from engine.core import InterviewEngine
from engine.utils import HINTS, EX_HINTS, CON_HINTS, hit_any, restore_categories_state
from engine.generators import generate_first_question, generate_question_llm, generate_material_gate_question

import redis

# ì‹¤ì œ í•¨ìˆ˜ êµ¬í˜„
def publish_delta_change(user_id, autobiography_id, theme_id, category_id, chunk_deltas=None, material_deltas=None):
    """ì‹¤ì œ ë³€í™”ëŸ‰ì„ CategoriesPayloadë¡œ ì „ì†¡"""
    try:
        # print(f"[DEBUG] publish_delta_change called with theme_id={theme_id}, category_id={category_id}")
        
        # serve ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€
        serve_dir = os.path.join(current_dir, '..', '..', '..', '..', 'serve')
        sys.path.insert(0, serve_dir)
        from stream import publish_categories_message
        from stream.dto import ChunksPayload, MaterialsPayload, CategoriesPayload
        
        # None ê°’ ì²´í¬
        if user_id is None or autobiography_id is None:
            print("[DEBUG] Skipping publish_delta_change due to None values")
            return
            
        # í˜„ì¬ ì‹œê°„
        from datetime import datetime, timezone
        timestamp = datetime.now(timezone.utc)
        
        # ChunksPayload ìƒì„± (chunk_idë¥¼ chunkOrderë¡œ ë§¤í•‘)
        chunks = []
        if chunk_deltas:
            for chunk_data in chunk_deltas:
                chunks.append(ChunksPayload(
                    categoryId=category_id,
                    chunkOrder=chunk_data.get('chunk_id', 0),  # chunk_id â†’ chunkOrder
                    weight=chunk_data.get('weight_delta', 0),   # ë³€í™”ëŸ‰
                    timestamp=timestamp
                ))
        
        # MaterialsPayload ìƒì„± (material_idë¥¼ materialOrderë¡œ ë§¤í•‘)
        materials = []
        if material_deltas:
            for material_data in material_deltas:
                materials.append(MaterialsPayload(
                    chunkId=material_data.get('chunk_id', 0),     # ì–´ëŠ chunkì— ì†í•˜ëŠ”ì§€
                    materialOrder=material_data.get('material_id', 0), # material_id â†’ materialOrder
                    example=material_data.get('example_delta', 0),     # ë³€í™”ëŸ‰
                    similarEvent=material_data.get('similar_event_delta', 0), # ë³€í™”ëŸ‰
                    count=material_data.get('count_delta', 0),         # ë³€í™”ëŸ‰
                    principle=material_data.get('principle_delta', [0,0,0,0,0,0]), # ë³€í™”ëŸ‰ ë°°ì—´
                    timestamp=timestamp
                ))
        
        # CategoriesPayload ìƒì„± ë° ì „ì†¡
        payload = CategoriesPayload(
            autobiographyId=int(autobiography_id),
            userId=int(user_id),
            themeId=theme_id,
            categoryId=category_id,
            chunks=chunks,
            materials=materials
        )
        
        # print(f"[AI_SEND] CategoriesPayload: autobiographyId={payload.autobiographyId}, userId={payload.userId}, themeId={payload.themeId}, categoryId={payload.categoryId}, chunks={len(payload.chunks)}, materials={len(payload.materials)}")
        
        publish_categories_message(payload)
        # print(f"[DEBUG] Published delta change: category={category_id}, {len(chunks)} chunks, {len(materials)} materials")
        
    except Exception as e:
        print(f"[WARN] Delta ë°œí–‰ ì‹¤íŒ¨: {e}")
        pass


# ------------------------ ê°„ë‹¨ í—¬í¼ ------------------------

def _norm(s: str) -> str:
    """ê³µë°± ì œê±° + trim í›„ ë¹„êµìš© ë¬¸ìì—´ë¡œ ì •ê·œí™”"""
    return re.sub(r"\s+", "", (s or "").strip())


def _build_materials_list_from_mapping(mapping_path: str) -> dict:
    """material_id_mapping.jsonì—ì„œ {name: [cat, chunk, mat]} dict ë°˜í™˜"""
    try:
        with open(mapping_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"[ERROR] material_id_mapping.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def _call_llm_map_flow(flow_path: str, answer_text: str, materials_list: dict, current_material: str, current_material_id: List[int]) -> List[dict]:
    """LLM í”Œë¡œìš° í˜¸ì¶œ"""
    if not os.path.exists(flow_path):
        return []

    try:
        from promptflow import load_flow
        flow = load_flow(flow_path)
        res = flow(answer_text=answer_text, materials_list=materials_list, current_material=current_material, current_material_id=current_material_id)
        items = res.get("analysis_result", [])
        
        print(f"[DEBUG] LLM raw response: {items}")
        
        # ë¬¸ìì—´ì´ë©´ JSON íŒŒì‹±
        if isinstance(items, str):
            items = items.strip()
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if items.startswith('```'):
                lines = items.split('\n')
                if lines[0].startswith('```'): lines = lines[1:]
                if lines and lines[-1].strip() == '```': lines = lines[:-1]
                items = '\n'.join(lines)
            items = json.loads(items)
        
        return items if isinstance(items, list) else []
    except Exception as e:
        print(f"[ERROR] LLM í”Œë¡œìš° í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return []
    
# AI cat_numì„ DBì˜ theme_id, category_orderë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_cat_num_to_db_mapping(cat_num):
    """AIì˜ cat_num(0-based)ì„ DBì˜ (theme_id, category_order)ë¡œ ë³€í™˜"""
    # material.jsonì˜ category orderì™€ DBì˜ theme-category ë§¤í•‘
    # material.json: order=1(ë¶€ëª¨), order=2(ì¡°ë¶€ëª¨), order=3(í˜•ì œ), order=4(ìë…€/ìœ¡ì•„), order=5(ì¹œì²™), order=6(ê°€ì¡±ì‚¬ê±´), order=7(ì£¼ê±°ì§€), order=8(ì„±ê²©), order=9(ê²°í˜¼), order=10(ë°°ìš°ì), order=11(ì¹œêµ¬), order=12(ì—°ì¸), order=13(ë°˜ë ¤ë™ë¬¼), order=14(ìƒì• ì£¼ê¸°), order=15(ì§ì¥), order=16(ì§„ë¡œ), order=17(ë¬¸ì œí•´ê²°), order=18(ì·¨ë¯¸), order=19(ê¸ˆì „), order=20(ì² í•™), order=21(ìƒí™œ)
    
    # DB ë§¤í•‘ (theme_id, category_order) - material.jsonì˜ order ê¸°ì¤€
    mapping = {
        1: (1, 1),   # ë¶€ëª¨
        2: (1, 2),   # ì¡°ë¶€ëª¨  
        3: (1, 3),   # í˜•ì œ
        4: (1, 4),   # ìë…€/ìœ¡ì•„
        5: (1, 5),   # ì¹œì²™
        6: (1, 6),   # ê°€ì¡± ì‚¬ê±´
        7: (4, 1),   # ì£¼ê±°ì§€
        8: (5, 1),   # ì„±ê²©
        9: (2, 2),   # ê²°í˜¼
        10: (2, 3),  # ë°°ìš°ì
        11: (6, 1),  # ì¹œêµ¬
        12: (2, 1),  # ì—°ì¸
        13: (12, 1), # ë°˜ë ¤ë™ë¬¼
        14: (8, 1),  # ìƒì• ì£¼ê¸°
        15: (7, 1),  # ì§ì¥
        16: (7, 2),  # ì§„ë¡œ
        17: (7, 3),  # ë¬¸ì œí•´ê²°(ê³¼ì •)
        18: (11, 1), # ì·¨ë¯¸
        19: (10, 1), # ê¸ˆì „
        20: (13, 1), # ì² í•™
        21: (14, 1), # ìƒí™œ
    }
    
    return mapping.get(cat_num, (1, 1))  # ê¸°ë³¸ê°’

@tool
def interview_engine(sessionId: str, answer_text: str, user_id: int, autobiography_id: int) -> Dict:
    """ì¸í„°ë·° ì—”ì§„ - Redisì—ì„œ ì„¸ì…˜ ë¡œë“œí•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±"""

    # Redisì—ì„œ ì„¸ì…˜ ë¡œë“œ
    import redis
    import os
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ Redis ì„¤ì • ì½ê¸°
    redis_host = os.getenv('REDIS_HOST')
    redis_port = int(os.getenv('REDIS_PORT'))
    redis_client = redis.Redis(host=redis_host, port=redis_port, db=0, decode_responses=True)
    session_key = f"session:{sessionId}"
    session_data_raw = redis_client.get(session_key)
    session_data = json.loads(session_data_raw) if session_data_raw and isinstance(session_data_raw, str) else None
    print(f"[DEBUG] Session loaded: session_data={session_data is not None}")
    if session_data:
        print(f"[DEBUG] last_question exists: {session_data.get('last_question') is not None}")
        if session_data.get('last_question'):
            print(f"[DEBUG] last_question: {session_data.get('last_question')}")

    # ì²« ì§ˆë¬¸ ë¶„ê¸°
    if not session_data or not session_data.get("last_question"):
        preferred_categories = session_data.get("metrics", {}).get("preferred_categories", []) if session_data else []

        material_json_path = os.path.join(os.path.dirname(__file__), "data", "material.json")
        with open(material_json_path, 'r', encoding='utf-8') as f:
            material_data = json.load(f)

        categories = InterviewEngine.build_categories_from_category_json(material_data)
        engine = InterviewEngine(categories)
        
        # í…Œë§ˆ ë¶€ìŠ¤íŒ… ì ìš©
        if preferred_categories:
            engine.boost_theme(preferred_categories, initial_weight=10)
            print(f"[DEBUG] í…Œë§ˆ ë¶€ìŠ¤íŒ… ì ìš©: {preferred_categories}")
            
            # preferred_categoriesê°€ ìˆìœ¼ë©´ material gate ì§ˆë¬¸ ìƒì„±
            material_id = engine.select_material()
            cat_num, chunk_num, mat_num = material_id
            material = engine._get_material(cat_num, chunk_num, mat_num)
            category = engine.categories[cat_num]
            chunk = category.chunks[chunk_num]
            full_material_name = f"{category.category_name} {chunk.chunk_name} {material.name}"
            
            gate_question_text = generate_material_gate_question(full_material_name)
            
            next_question = {
                "id": f"q-{uuid4().hex[:8]}",
                "material": {
                    "full_material_name": full_material_name,
                    "full_material_id": list(material_id),
                    "material_name": material.name,
                    "material_order": material.order
                },
                "type": "material_gate",
                "text": gate_question_text
            }
            
            def serialize_categories(categories):
                result = []
                for cat in categories.values():
                    active_chunks = {ck: cv for ck, cv in cat.chunks.items() if cat.chunk_weight.get(ck, 0) > 0}
                    if not active_chunks:
                        continue
                    chunks = []
                    for chunk in active_chunks.values():
                        materials = [
                            {"order": m.order, "name": m.name, "principle": m.principle,
                             "example": m.example, "similar_event": m.similar_event, "count": m.count}
                            for m in chunk.materials.values()
                            if any(m.principle) or m.example or m.similar_event or m.count > 0
                        ]
                        if materials:
                            chunks.append({"chunk_num": chunk.chunk_num, "chunk_name": chunk.chunk_name, "materials": materials})
                    if chunks:
                        result.append({
                            "category_num": cat.category_num,
                            "category_name": cat.category_name,
                            "chunks": chunks,
                            "chunk_weight": {str(ck): w for ck, w in cat.chunk_weight.items() if w > 0}
                        })
                return result
            
            updated_metrics = {
                "session_id": sessionId,
                "categories": serialize_categories(engine.categories),
                "engine_state": {
                    "last_material_id": list(engine.state.last_material_id) if engine.state.last_material_id else [],
                    "last_material_streak": engine.state.last_material_streak,
                    "epsilon": engine.state.epsilon
                },
                "asked_total": 1,
                "preferred_categories": preferred_categories,
                "policy_version": "v0.5.0"
            }
            
            session_update = {
                "metrics": updated_metrics,
                "last_question": next_question,
                "updated_at": time.time()
            }
            redis_client.setex(session_key, 3600, json.dumps(session_update))
            
            print(f"\nğŸš§ [ì²« ì§ˆë¬¸ - Material Gate] {full_material_name}")
            return {"next_question": next_question, "last_answer_materials_id": []}
        else:
            # preferred_categoriesê°€ ì—†ìœ¼ë©´ ììœ  ì§ˆë¬¸
            metrics = {"preferred_categories": preferred_categories}
            result = generate_first_question(engine, metrics)
            if result.get("next_question") and "material_id" in result["next_question"]:
                material_id = result["next_question"].pop("material_id")
                result["next_question"]["material"]["full_material_id"] = material_id
            result["last_answer_materials_id"] = []
            return result

    # ì´í›„ ì§ˆë¬¸ ìƒì„± ì¤€ë¹„
    question = session_data.get("last_question", {})
    metrics = session_data.get("metrics", {})
    
    # material.json ë¡œë“œ ë° ì—”ì§„ ì´ˆê¸°í™”
    material_json_path = os.path.join(os.path.dirname(__file__), "data", "material.json")
    try:
        with open(material_json_path, 'r', encoding='utf-8') as f:
            material_data = json.load(f)

        categories = InterviewEngine.build_categories_from_category_json(material_data)

        # ì´ì „ ë©”íŠ¸ë¦­ì´ ìˆìœ¼ë©´ ìƒíƒœ ë³µì›
        if metrics.get("categories"):
            restore_categories_state(categories, metrics["categories"])

        engine = InterviewEngine(categories)

        # ìƒíƒœ ë³µì›
        engine_state = metrics.get("engine_state", {})
        engine.state.last_material_id = engine_state.get("last_material_id")
        engine.state.last_material_streak = engine_state.get("last_material_streak", 0)
        engine.theme_initialized = engine_state.get("theme_initialized", False)

    except Exception as e:
        print(f"[ERROR] ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return {"next_question": None, "last_answer_materials_id": []}

    # ë‹µë³€ ë¶„ì„
    current_material = question.get("material", "") if question else ""
    # material_idëŠ” material.full_material_id ë˜ëŠ” ìµœìƒìœ„ material_idì—ì„œ ê°€ì ¸ì˜¤ê¸° (í•˜ìœ„ í˜¸í™˜)
    current_material_id = None
    if isinstance(current_material, dict):
        current_material_id = current_material.get("full_material_id")
    if not current_material_id:
        current_material_id = question.get("material_id") if question else None
    is_first_question = not answer_text or not current_material
    
    # í˜„ì¬ ì§ˆë¬¸ ì†Œì¬ì˜ full_material_name ì°¾ê¸° (LLMì— ì „ë‹¬ìš©)
    current_material_full = ""
    if isinstance(current_material, dict):
        current_material_full = current_material.get("full_material_name", "")
    elif isinstance(current_material, str):
        current_material_full = current_material
    
    # full_material_nameì´ ì—†ìœ¼ë©´ material_idë¡œ ì—­ê²€ìƒ‰
    if not current_material_full and current_material_id and isinstance(current_material_id, list) and len(current_material_id) == 3:
        cat_num, chunk_num, mat_num = current_material_id
        temp_cat = engine.categories.get(cat_num)
        if temp_cat:
            temp_chunk = temp_cat.chunks.get(chunk_num)
            if temp_chunk:
                temp_mat = temp_chunk.materials.get(mat_num)
                if temp_mat:
                    current_material_full = f"{temp_cat.category_name} {temp_chunk.chunk_name} {temp_mat.name}"

    matched_materials: List[str] = []
    axes_analysis_by_material: Dict[str, dict] = {}
    mapped_ids: List[List[int]] = []

    if not is_first_question:
        # 6W ì¶• ê°ì§€(íœ´ë¦¬ìŠ¤í‹±, LLM ë°˜í™˜ì— ê°’ ì—†ì„ ë•Œ ë³´ì¡°ë¡œ ì‚¬ìš©)
        axes_evidence = {k: hit_any(answer_text, HINTS[k]) for k in HINTS.keys()}
        ex_flag = 1 if hit_any(answer_text, EX_HINTS) else 0
        con_flag = 1 if hit_any(answer_text, CON_HINTS) else 0
        if not con_flag and len(answer_text or "") >= 80:
            con_flag = 1

        # ìƒëŒ€ê²½ë¡œë¡œ map flow ì°¾ê¸°
        map_flow_path = os.path.normpath(os.path.join(current_dir, "..", "..", "standard", "map_answer_to_materials", "flow.dag.yaml"))
        mapping_path = os.path.join(os.path.dirname(__file__), "data", "material_id_mapping.json")
        materials_list = _build_materials_list_from_mapping(mapping_path)

        llm_items = _call_llm_map_flow(map_flow_path, answer_text, materials_list, current_material_full, list(current_material_id) if current_material_id else [])

        # ì†Œì¬ ë§¤ì¹­
        print(f"[DEBUG] LLM items count: {len(llm_items)}")
        for item in llm_items:
            if not isinstance(item, dict) or not item.get("material"):
                print(f"[DEBUG] Skipping invalid item: {item}")
                continue
            
            material_id = item["material"]
            print(f"[DEBUG] material_id type: {type(material_id)}, value: {material_id}")
            
            # material_idëŠ” [cat, chunk, mat] í˜•íƒœì—¬ì•¼ í•¨
            if not isinstance(material_id, list) or len(material_id) != 3:
                print(f"[DEBUG] Invalid material_id format: {material_id}")
                continue
            
            # ì†Œì¬ ì´ë¦„ ì°¾ê¸°
            cat_num, chunk_num, mat_num = material_id
            temp_cat = engine.categories.get(cat_num)
            if not temp_cat:
                print(f"[DEBUG] Category {cat_num} not found")
                continue
            
            temp_chunk = temp_cat.chunks.get(chunk_num)
            if not temp_chunk:
                print(f"[DEBUG] Chunk {chunk_num} not found in category {cat_num}")
                continue
            
            temp_mat = temp_chunk.materials.get(mat_num)
            if not temp_mat:
                print(f"[DEBUG] Material {mat_num} not found in chunk {chunk_num}")
                continue
            
            material_name = f"{temp_cat.category_name} {temp_chunk.chunk_name} {temp_mat.name}"
            matched_materials.append(material_name)
            axes_analysis_by_material[material_name] = item.get("axes", {})
            mapped_ids.append(material_id)
            print(f"[DEBUG] Mapped to ID: {material_id}, name: {material_name}")

        # LLM ë¶„ì„ ê²°ê³¼ ë°˜ì˜
        for i, material_id in enumerate(mapped_ids):
            cat_num, chunk_num, mat_num = material_id
            material = engine._get_material(cat_num, chunk_num, mat_num)
            if not material:
                continue

            axes_data = axes_analysis_by_material.get(matched_materials[i], {})
            is_pass = axes_data.get("pass", 0) == 1

            if is_pass:
                # íšŒí”¼/ë°˜ê° ì‘ë‹µ: ì†Œì¬ ì™„ë£Œ ì²˜ë¦¬
                material.principle = [1, 1, 1, 1, 1, 1]
                material.example, material.similar_event = 1, 1
                material.count = 1
                print(f"[INFO] íšŒí”¼/ë°˜ê° ê°ì§€: {matched_materials[i]} - ì†Œì¬ ì™„ë£Œ ì²˜ë¦¬")
            else:
                # ì •ìƒ ì‘ë‹µ - principle (6W)
                principle = axes_data.get("principle", [])
                if isinstance(principle, list) and len(principle) == 6:
                    for j, val in enumerate(principle):
                        if val == 1: material.principle[j] = 1
                else:
                    # íœ´ë¦¬ìŠ¤í‹± ë³´ì¡°
                    for j, val in enumerate(axes_evidence.values()):
                        if val and j < 6: material.principle[j] = 1

                # example / similar_event
                if axes_data.get("example") == 1 or ex_flag: material.example = 1
                if axes_data.get("similar_event") == 1 or con_flag: material.similar_event = 1

            # ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ ê°±ì‹ 
            category = engine.categories[cat_num]
            category.chunk_weight[chunk_num] = category.chunk_weight.get(chunk_num, 0) + 1
            material.mark_filled_if_ready()

        print(f"\nğŸ” [ì†Œì¬ ë§¤ì¹­] {current_material} â†’ {matched_materials}")
    # ------------------ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ------------------

    try:
        material_id = engine.select_material()
        cat_num, chunk_num, mat_num = material_id

        material = engine._get_material(cat_num, chunk_num, mat_num)
        if not material:
            return {"next_question": None, "last_answer_materials_id": []}

        # Material Gate ì²´í¬: ì†Œì¬ì— ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ gate ì§ˆë¬¸ ë¨¼ì €
        category = engine.categories[cat_num]
        chunk = category.chunks[chunk_num]
        full_material_name = f"{category.category_name} {chunk.chunk_name} {material.name}"
        
        # ì§ì „ ì§ˆë¬¸ì´ gateê°€ ì•„ë‹ˆê³ , í˜„ì¬ ì†Œì¬ê°€ ì™„ì „íˆ ë¹„ì–´ìˆìœ¼ë©´ gate ì§ˆë¬¸ ìƒì„±
        # ë‹¨, ì§ì „ ì§ˆë¬¸ì´ gateì˜€ì–´ë„ ë‹¤ë¥¸ ì†Œì¬ë¡œ ë°”ë€Œì—ˆìœ¼ë©´ gate ì§ˆë¬¸ ìƒì„±
        last_question_type = question.get("type") if question else None
        # material_idëŠ” material.full_material_id ë˜ëŠ” ìµœìƒìœ„ material_idì—ì„œ ê°€ì ¸ì˜¤ê¸°
        last_material_id = None
        if isinstance(current_material, dict):
            last_material_id = tuple(current_material.get("full_material_id", [])) if current_material.get("full_material_id") else None
        if not last_material_id:
            last_material_id = tuple(question.get("material_id")) if question and question.get("material_id") else None
        is_material_empty = (material.progress_score() == 0 and material.count == 0)
        is_different_material = (last_material_id != material_id)
        
        print(f"[DEBUG] Gate ì²´í¬: material_id={material_id}, progress_score={material.progress_score()}, count={material.count}, last_type={last_question_type}")
        print(f"[DEBUG] is_material_empty={is_material_empty}, principle={material.principle}, ex={material.example}, con={material.similar_event}")
        print(f"[DEBUG] last_material_id={last_material_id}, is_different_material={is_different_material}")
        
        if is_material_empty and (last_question_type != "material_gate" or is_different_material):
            gate_question_text = generate_material_gate_question(full_material_name)
            
            # material.name ì§ì ‘ ì‚¬ìš©
            material_name = material.name
            
            next_question = {
                "id": f"q-{uuid4().hex[:8]}",
                "material": {
                    "full_material_name": full_material_name,
                    "full_material_id": list(material_id),
                    "material_name": material_name,
                    "material_order": material.order
                },
                "type": "material_gate",
                "text": gate_question_text
            }
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (ìƒíƒœëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ)
            def serialize_categories(categories):
                result = []
                for cat in categories.values():
                    active_chunks = {ck: cv for ck, cv in cat.chunks.items() if cat.chunk_weight.get(ck, 0) > 0}
                    if not active_chunks:
                        continue

                    chunks = []
                    for chunk in active_chunks.values():
                        materials = [
                            {"order": m.order, "name": m.name, "principle": m.principle,
                             "example": m.example, "similar_event": m.similar_event, "count": m.count}
                            for m in chunk.materials.values()
                            if any(m.principle) or m.example or m.similar_event or m.count > 0
                        ]
                        if materials:
                            chunks.append({"chunk_num": chunk.chunk_num, "chunk_name": chunk.chunk_name, "materials": materials})

                    if chunks:
                        result.append({
                            "category_num": cat.category_num,
                            "category_name": cat.category_name,
                            "chunks": chunks,
                            "chunk_weight": {str(ck): w for ck, w in cat.chunk_weight.items() if w > 0}
                        })
                return result
            
            updated_metrics = {
                "session_id": sessionId,
                "categories": serialize_categories(engine.categories),
                "engine_state": {
                    "last_material_id": list(engine.state.last_material_id) if engine.state.last_material_id else [],
                    "last_material_streak": engine.state.last_material_streak,
                    "epsilon": engine.state.epsilon
                },
                "asked_total": metrics.get("asked_total", 0) + 1,
                "policy_version": "v0.5.0"
            }
            
            session_update = {
                "metrics": updated_metrics,
                "last_question": next_question,
                "updated_at": time.time()
            }
            redis_client.setex(session_key, 3600, json.dumps(session_update))
            
            print(f"\nğŸš§ [Material Gate] {full_material_name} - ì§„ì… í™•ì¸ ì§ˆë¬¸ ìƒì„±")
            if last_question_type == "material_gate" and is_different_material:
                print(f"   (ì§ì „ë„ gateì˜€ì§€ë§Œ ì†Œì¬ ë³€ê²½: {last_material_id} â†’ {material_id})")
            print("=" * 50)
            
            return {"next_question": next_question, "last_answer_materials_id": mapped_ids if mapped_ids else []}

        material_id, target = engine.select_question_in_material(material_id)
        if not target:
            return {"next_question": None, "last_answer_materials_id": []}
        
        print(f"[DEBUG] select_question_in_material í›„: material_id={material_id}, target={target}")
        
        # ì†Œì¬ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if material_id != (cat_num, chunk_num, mat_num):
            print(f"[DEBUG] ì†Œì¬ ë³€ê²½ë¨: {(cat_num, chunk_num, mat_num)} -> {material_id}")
            # ë³€ê²½ëœ ì†Œì¬ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
            cat_num, chunk_num, mat_num = material_id
            material = engine._get_material(cat_num, chunk_num, mat_num)
            category = engine.categories[cat_num]
            chunk = category.chunks[chunk_num]
            full_material_name = f"{category.category_name} {chunk.chunk_name} {material.name}"

        # íƒ€ì… ë§¤í•‘: ì—”ì§„ íƒ€ì… â†’ í”„ë¡¬í”„íŠ¸ íƒ€ì…
        type_mapping = {
            "w1": "when_where",
            "w2": "how1",
            "w3": "who",
            "w4": "what",
            "w5": "how2",
            "w6": "why",
            "ex": "ex",
            "con": "con"
        }
        prompt_type = type_mapping.get(target, target)

        # ì¹´í…Œê³ ë¦¬ê°€ ê°™ìœ¼ë©´ ì´ì „ ë‹µë³€ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬
        context_answer = None
        if not is_first_question and last_material_id:
            last_cat_num = last_material_id[0] if isinstance(last_material_id, (list, tuple)) and len(last_material_id) >= 1 else None
            current_cat_num = material_id[0]
            if last_cat_num == current_cat_num:
                context_answer = answer_text
                print(f"[DEBUG] ê°™ì€ ì¹´í…Œê³ ë¦¬({current_cat_num}) - ì´ì „ ë‹µë³€ ì „ë‹¬")
            else:
                print(f"[DEBUG] ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬({last_cat_num} â†’ {current_cat_num}) - ì´ì „ ë‹µë³€ ë¯¸ì „ë‹¬")

        question_text = generate_question_llm(full_material_name, prompt_type, context_answer)

        # streak ì—…ë°ì´íŠ¸
        if engine.state.last_material_id == material_id:
            engine.state.last_material_streak += 1
        else:
            engine.state.last_material_id = material_id
            engine.state.last_material_streak = 1

        # material.name ì§ì ‘ ì‚¬ìš©
        material_name = material.name
        
        next_question = {
            "id": f"q-{uuid4().hex[:8]}",
            "material": {
                "full_material_name": full_material_name,
                "full_material_id": list(material_id),
                "material_name": material_name,
                "material_order": material.order
            },
            "type": target,
            "text": question_text
        }

        def serialize_categories(categories):
            result = []
            for cat in categories.values():
                active_chunks = {ck: cv for ck, cv in cat.chunks.items() if cat.chunk_weight.get(ck, 0) > 0}
                if not active_chunks:
                    continue

                chunks = []
                for chunk in active_chunks.values():
                    materials = [
                        {"order": m.order, "name": m.name, "principle": m.principle,
                         "example": m.example, "similar_event": m.similar_event, "count": m.count}
                        for m in chunk.materials.values()
                        if any(m.principle) or m.example or m.similar_event or m.count > 0
                    ]
                    if materials:
                        chunks.append({"chunk_num": chunk.chunk_num, "chunk_name": chunk.chunk_name, "materials": materials})

                if chunks:
                    result.append({
                        "category_num": cat.category_num,
                        "category_name": cat.category_name,
                        "chunks": chunks,
                        "chunk_weight": {str(ck): w for ck, w in cat.chunk_weight.items() if w > 0}
                    })
            return result

        updated_metrics = {
            "session_id": sessionId,
            "categories": serialize_categories(engine.categories),
            "engine_state": {
                "last_material_id": list(engine.state.last_material_id) if engine.state.last_material_id else [],
                "last_material_streak": engine.state.last_material_streak,
                "epsilon": engine.state.epsilon
            },
            "asked_total": metrics.get("asked_total", 0) + 1,
            "policy_version": "v0.5.0"
        }
        
        # ì´ì „ ìƒíƒœ ì €ì¥
        previous_categories = metrics.get("categories", [])
        
        # Delta ê³„ì‚° ë° ë°œí–‰
        try:
            from datetime import datetime, timezone
            serve_dir = os.path.join(current_dir, '..', '..', '..', '..', 'serve')
            sys.path.insert(0, serve_dir)
            from stream import publish_categories_message
            from stream.dto import ChunksPayload, MaterialsPayload, CategoriesPayload
            
            now = datetime.now(timezone.utc)
            prev_cats = {c["category_num"]: c for c in previous_categories}
            
            for curr_cat in updated_metrics["categories"]:
                cat_num = curr_cat["category_num"]
                prev_cat = prev_cats.get(cat_num, {})
                prev_chunks = {c["chunk_num"]: c for c in prev_cat.get("chunks", [])}
                chunks_deltas = []
                materials_deltas = []
                
                for curr_chunk in curr_cat["chunks"]:
                    chunk_num = curr_chunk["chunk_num"]
                    prev_chunk = prev_chunks.get(chunk_num, {})
                    
                    # chunk weight ë³€í™”
                    prev_weight = prev_chunk.get("chunk_weight", {}).get(str(chunk_num), 0) if prev_chunk else 0
                    curr_weight = curr_cat["chunk_weight"].get(str(chunk_num), 0)
                    
                    if curr_weight > prev_weight:
                        chunks_deltas.append(ChunksPayload(
                            categoryId=cat_num, chunkOrder=chunk_num,
                            weight=curr_weight - prev_weight, timestamp=now
                        ))
                    
                    # material ë³€í™”
                    prev_materials = {m["order"]: m for m in prev_chunk.get("materials", [])}
                    for curr_mat in curr_chunk["materials"]:
                        mat_order = curr_mat["order"]
                        prev_mat = prev_materials.get(mat_order, {})
                        
                        principle_delta = [curr_mat["principle"][i] - prev_mat.get("principle", [0,0,0,0,0,0])[i] for i in range(6)]
                        example_delta = curr_mat["example"] - prev_mat.get("example", 0)
                        similar_event_delta = curr_mat["similar_event"] - prev_mat.get("similar_event", 0)
                        count_delta = curr_mat["count"] - prev_mat.get("count", 0)
                        
                        if any(principle_delta) or example_delta or similar_event_delta or count_delta:
                            materials_deltas.append(MaterialsPayload(
                                chunkId=chunk_num, materialOrder=mat_order,
                                example=example_delta, similarEvent=similar_event_delta,
                                count=count_delta, principle=principle_delta, timestamp=now
                            ))
                
                if chunks_deltas or materials_deltas:
                    # AI cat_numì„ DB ë§¤í•‘ìœ¼ë¡œ ë³€í™˜
                    theme_id, category_order = convert_cat_num_to_db_mapping(cat_num)
                    
                    final_payload = CategoriesPayload(
                        autobiographyId=int(autobiography_id),  # str() ì œê±°í•˜ê³  int() ì‚¬ìš©
                        userId=int(user_id),  # str() ì œê±°í•˜ê³  int() ì‚¬ìš©
                        themeId=theme_id,  # ì˜¬ë°”ë¥¸ theme_id ì‚¬ìš©
                        categoryId=category_order,  # DBì˜ category_order ì‚¬ìš©
                        chunks=chunks_deltas, materials=materials_deltas
                    )
                    
                    # print(f"[AI_SEND_FINAL] CategoriesPayload: autobiographyId={final_payload.autobiographyId}, userId={final_payload.userId}, themeId={final_payload.themeId}, categoryId={final_payload.categoryId}, chunks={len(final_payload.chunks)}, materials={len(final_payload.materials)}")
                    
                    publish_categories_message(final_payload)
        except Exception as e:
            print(f"[WARN] Delta ë°œí–‰ ì‹¤íŒ¨: {e}")

        session_update = {
            "metrics": updated_metrics,
            "last_question": next_question,
            "updated_at": time.time()
        }
        redis_client.setex(session_key, 3600, json.dumps(session_update))

        print(f"\nğŸ¯ [ì§ˆë¬¸ ìƒì„±] {category.category_name}-{chunk.chunk_name}-{material.name} ({target})")
        print(f"[DEBUG] ì„ íƒëœ ì†Œì¬ ID: {material_id}, chunk_weight: {category.chunk_weight.get(chunk_num, 0)}, progress_score: {material.progress_score()}")
        print("=" * 50)

        last_answer_materials_id = mapped_ids if mapped_ids else []
        return {"next_question": next_question, "last_answer_materials_id": last_answer_materials_id}

    except Exception as e:
        print(f"[ERROR] ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"next_question": None, "last_answer_materials_id": []}